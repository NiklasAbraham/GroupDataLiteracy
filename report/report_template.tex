%!TEX root = report_template.tex

%%%%%%%% DATA LITERACY 2025 LATEX PROJECT TEMPLATE FILE %%%%%%%%%%%%%%%%%
%%% Based on the 2025 ICML template, available at https://icml.cc/Conferences/2025/AuthorInstructions %%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{makecell} % for multi-line table cells
\usepackage{amsmath}   % For \text{}, align environments, better math spacing
\usepackage{amssymb}   % For \mathbb, extra symbols (optional but common)
\usepackage{booktabs}
\usepackage{multirow}


\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, calc, fit}
% Corporate Design of the University of Tübingen
% Primary Colors
\definecolor{TUred}{RGB}{165,30,55}
\definecolor{TUgold}{RGB}{180,160,105}
\definecolor{TUdark}{RGB}{50,65,75}
\definecolor{TUgray}{RGB}{175,179,183}

% Secondary Colors
\definecolor{TUdarkblue}{RGB}{65,90,140}
\definecolor{TUblue}{RGB}{0,105,170}
\definecolor{TUlightblue}{RGB}{80,170,200}
\definecolor{TUlightgreen}{RGB}{130,185,160}
\definecolor{TUgreen}{RGB}{125,165,75}
\definecolor{TUdarkgreen}{RGB}{50,110,30}
\definecolor{TUocre}{RGB}{200,80,60}
\definecolor{TUviolet}{RGB}{175,110,150}
\definecolor{TUmauve}{RGB}{180,160,150}
\definecolor{TUbeige}{RGB}{215,180,105}
\definecolor{TUorange}{RGB}{210,150,0}
\definecolor{TUbrown}{RGB}{145,105,70}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Project Report Template for Data Literacy 2025}

\begin{document}

\twocolumn[
% \icmltitle{The Geometry of Cinema: Quantifying 75 Years of Cultural Drift}
\icmltitle{Plot Twists Over Time: How Movie Stories Have Changed over 95 Years}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Ansel Cheung}{equal,first}
\icmlauthor{Alessio Villa}{equal,second}
\icmlauthor{Bartol Markovinović}{equal,third}
\icmlauthor{Martín López de Ipi\~na}{equal,fourth}
\icmlauthor{Niklas Abraham}{equal,fifth}
\end{icmlauthorlist}

% fill in your matrikelnummer, email address, degree, for each group member
\icmlaffiliation{first}{Matrikelnummer 7274374, MSc Machine Learning}
\icmlaffiliation{second}{Matrikelnummer 7306912, MSc Computer Science}
\icmlaffiliation{third}{Matrikelnummer 7324790, MSc Machine Learning}
\icmlaffiliation{fourth}{Matrikelnummer 7293076, MSc Machine Learning}
\icmlaffiliation{fifth}{Matrikelnummer 7307188, MSc Machine Learning}

% put your email addresses here. You can use initials to save space, 
% e.g. if you are called Max Mustermann, you can use \icmlcorrespondingauthor{MM}{max.mustermann@uni-tuebingen.de}
% DO USE YOUR UNIVERSITY EMAIL ADDRESS!
\icmlcorrespondingauthor{Initials1}{ansel-heng-yu.cheung@uni-tuebingen.de} 
\icmlcorrespondingauthor{Initials2}{alessio.villa@student.uni-tuebingen.de}
\icmlcorrespondingauthor{Initials3}{bartol.markovinovic@student.uni-tuebingen.de}
\icmlcorrespondingauthor{Initials4}{martin.lopez-de-ipina-munoz@student.uni-tuebingen.de}
\icmlcorrespondingauthor{Initials5}{niklas-sebastian.abraham@student.uni-tuebingen.de}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
We analyze semantic evolution in cinema by embedding movie plot summaries from 1930 to 2024 into a unified semantic space. Using distance distributions, novelty scores, and statistical tests, we quantify how genres and thematic clusters shift over time. Our analysis reveals periods of semantic stability and reorganization, providing quantitative measures of cultural change in narrative structures across nearly a century of cinema.
\end{abstract}

\section{Introduction}\label{sec:intro}

Cinema provides a rich archive of narrative structures that encode evolving societal values across generations. Previous approaches employ keyword search or topic modelling \cite{dubourg2023cinema} to explore temporal trends in movie plots. While these older methods might be insightful but challenging, recent computational work \cite{xu2020cinderella} has revealed hidden cultural patterns in large narrative corpora. One such analysis conducted on musical domain uses high dimensional embeddings to observe changes to structural properties over time \cite{DiMarco2025}. We build upon these foundations by leveraging advances in large language models (LLMs) to embed movie plot summaries \cite{sreenivasan2013quantitative} into a unified semantic space. Using novel statistical methods, we quantitatively analyze how movie narrative evolve over time.

\section{Data and Methods}\label{sec:methods}

\subsection{Data Collection}

We constructed our movie corpus using a multi stage pipeline that systematically integrated three complementary sources: Wikidata, The Movie Database (TMDb), and Wikipedia. This approach combines rich structured metadata with the detailed textual content required for semantic analysis.

Initial dataset was constructed by querying Wikidata for movies released from 1930 to 2024. In order to adhere to Wikidata's query size limitations, we iterated through the years and first acquired QIDs of all Wikidata items which have a Wikidata class that is an indirect subclass of film and have a first publication date in the given year. During this step we removed QIDs of items that do not have an English Wikipedia page associated with them. We also tried to remove non-feature movies by excluding subclasses of classes "short film" and "television series episode". However, this filtering was not perfect and further filtering of Wikidata classes was performed during post processing. After acquiring the list of identifiers, we processed them in small batches of 20 and queried Wikidata for each movie's features including title, release date, duration, genres, directors, actors, English Wikipedia link, and very importantly links to external movie databases TMDb and IMDb. Additionally, box office, box office currency, budget and budget currency values were also queried, but they had very low coverage in the raw dataset and were not used in the final analysis.

Second, we enriched the dataset using TMDb, a community driven database that offers quantitative measures of popularity and user engagement. Wikidata's external identifiers enabled direct mapping to TMDb entries, from which we programmatically retrieved vote counts, vote averages, and popularity metrics for each film. These measures served as proxies for audience engagement and cultural impact, informing downstream film filtering and weighting.

The third stage, the most data intensive, focused on obtaining full text plot summaries. Leveraging Wikipedia sitelinks from Wikidata, we accessed each film's Wikipedia page to extract the plot section. Wikipedia's editorial standards ensure relatively uniform and neutral plot descriptions, facilitating standardized comparative semantic analysis. This step used the Wikipedia API for article retrieval, section extraction, and text normalization, transforming metadata into the dense textual data required for downstream embedding.

The last enrichment stage addressed limitations in TMDb voting statistics. Many movies in the corpus lacked TMDb ratings or vote counts, and when available, these counts were often substantially lower than those reported by other platforms. To address this issue, we enriched the dataset with IMDb vote averages and vote counts, obtained from IMDb's non-commercial data files and merged using the IMDb title identifier. The inclusion of IMDb data ensures broader coverage and higher vote volumes, resulting in a more stable measure of audience reception.

All data sources are open and appropriately licensed. Wikidata \cite{wikidata} is released under CC0 1.0 Universal (public domain). Wikipedia \cite{wikipedia} is under CC BY SA 4.0, and TMDb \cite{tmdb} under CC BY NC 4.0, allowing non commercial research with attribution. This ensures reproducibility and legal compliance.

After the data was collected in a tabular format, the textual plot descriptions required transformation into vector representations via a suitable embedding model for downstream analysis. The plot descriptions extracted from Wikipedia pages exhibit substantial variability in length, ranging from 10 to 20,479 characters, corresponding to approximately 6 to 5,296 tokens in an English tokenizer. All plot descriptions in our corpus are in English, which simplifies the embedding process by eliminating cross lingual considerations. After performing the explicitly described data pipeline steps, the final dataset contained 161{,}533 data points (movies) with a average coverage of 81\% in the categories of actors, directors, genres, and year.

\subsection{Data cleaning}

After collecting the raw movie data from Wikidata, TMDb and Wikipedia, we first ensured that our dataset does not contain any duplicates with respect to Wikidata QIDs and Wikipedia links. Then we performed the following data filtration and cleaning steps:

\begin{itemize}
    \item \textbf{Filtering out movies without a Wikipedia plot.}
    \item \textbf{Removal of non feature movies.} We removed samples from our dataset that had a Wikidata class that is an indirect subclass of a class that does not describe a feature movie. Some examples of not feasible Wikidata classes include trailers, television series episodes, short films and radio programs. 
    \item \textbf{Filtering out movies with excessively long plots.} We filtered out movies with plots longer than 14,000 characters from our dataset because these plots are labeled by Wikipedia as \textit{excessively long}.
    \item \textbf{Removal of movies with low entropy plots.}
    \item \textbf{Genre filtering.} We filtered out genres that appear only once in the dataset because these genres obviously do not describe a group of movies.
    \item \textbf{Exclusion of explicit content.} We excluded movies whose primary genres fell within explicit or highly exploitative categories, such as Bavarian porn, Nazi exploitation, cannibal film, cartoon pornography, erotic film, sexploitation film, and related genres. These categories were removed in order to focus our analysis on mainstream cinematic narratives, to avoid the distorting effects that fringe, pornographic, or exploitation genres would have on cultural and semantic trends in the wider corpus, and because including them would not have been appropriate or useful for a university project of this scope.
\end{itemize}

The most critical cleaning step was the removal of movies with low-entropy plots. Raw dataset contained a significant number of incomplete or overly brief plots (e.g. \href{https://en.wikipedia.org/wiki/1982_(2013_film)}{this}). To identify and remove such movies we employed a filtering method inspired by \cite{wenzek2019ccnetextractinghighquality}, who used perplexity of a Large Language model to filter out low quality documents. While \cite{wenzek2019ccnetextractinghighquality} utilized perplexity of a 5 gram language model trained on high quality data, we tokenized the plots with the BGE-M3 tokenizer and compute the Shannon entropy of the token distribution for each plot. To determine the optimal entropy threshold, we sampled 150 movies from the borderline entropy region of $[4.0, 5.5]$ and manually annotated them as either \textit{good} or \textit{bad} quality. The threshold of $4.8398$ was chosen to maximize the $F\beta$ score with $\beta=0.5$ prioritizing precision over recall.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/funnel_chart_data_cleaning.png}
    \caption{Data cleaning pipeline: number of movies retained after each filtering step.}
    \label{fig:data_cleaning_funnel}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/entropy_cutoff.png}
    \caption{Results of manual labeling of 150 plots in the borderline entropy region with the chosen entropy threshold}
    \label{fig:entropy_cutoff}
\end{figure}

\subsubsection{Embedding of the movie plot summaries}

The selection of an appropriate embedding model was guided by the Massive Text Embedding Benchmark (MTEB) leaderboard results\footnote{\url{https://huggingface.co/spaces/mteb/leaderboard}}, which provides comprehensive evaluations of embedding models across diverse retrieval and semantic similarity tasks. Based on these benchmarks, we selected the BGE-M3 (Beijing Academy of Artificial Intelligence Multilingual, Multifunctional, Multi granularity) model \cite{chen2024bgem3embeddingmultilingualmultifunctionality}. The BGE-M3 model achieved competitive performance (28th place on the MTEB leaderboard) while maintaining a relatively compact architecture with 0.5 billion parameters. Critically, the model supports a context length of 8,192 tokens, which enables embedding entire movie plot descriptions into a single vector representation without requiring chunking.

A key methodological choice was to use a single, static embedding model for all time periods, rather than training separate or temporally aligned models. This ensures all film plots are represented in a unified latent space, avoiding complex post hoc alignment and minimizing artifacts. The Wikipedia based plot summaries are not contemporaneous texts from those eras, instead, they are modern English descriptions collectively maintained and updated since Wikipedia's founding in 2001. Thus, any linguistic variation or semantic drift in the summaries themselves is minimal. We evaluated several document embedding methods (chunking and pooling) and metrics as described in \cite{DBLP:journals/corr/abs-1810-04805, pmlr-v97-gong19a, raffel2023exploringlimitstransferlearning}, and selected CLS Token as our approach.

\subsubsection{Internal data validation}

To check that the embeddings meaningfully represent plot similarity, we measured cosine distances within and outside major movie franchises (Harry Potter, Star Wars, James Bond). Movies from the same franchise consistently clustered closer together (e.g., Harry Potter: 0.21 inner-group distance vs. 0.57 to random movies), while the global average distance between any two movies was 0.52. This confirms that the embeddings capture true semantic similarity.

\subsubsection{Genre Taxonomy}

The raw dataset included 975 unique genre labels, many of which were redundant or highly similar. To simplify and standardize the taxonomy, we first removed genres that appeared only once, reducing the set to 463. We then embedded the Wikipedia descriptions (available for 359 genres) using the BGE-M3 model, and clustered these vectors with $k=20$ using k-means. Each cluster was manually labeled based on thematic similarity, resulting in 20 coherent genre categories used in further analyses.

\subsubsection{Genre stability}



\subsection{Novelty analysis}

This part in introduction maybe:
Common public sentiment is that the film industry is "running out of ideas" resulting in movies that are becoming less creative and more similar to each other over time.

Then later:
To investigate the claim that movies are becoming less novel over time, we developed a metric for novelty defined as the minimal cosine distance between a specific movie's plot embedding and the embeddings of all movies in the dataset released prior to it. This can be formally written as:

\begin{equation}
    \text{Novelty}(m_i) = \min_{j: year_j < year_i} \left( 1 - \frac{E(m_i) \cdot E(m_j)}{\|E(m_i)\| \|E(m_j)\|} \right)
\end{equation} 

where \( E(m) \) denotes the embedding vector of a movie's plot.
Intuitively, a higher novelty score indicates that the movie's plot is more dissimilar from prior movies, while a lower score implies existence of a very similar movie released earlier.
To compiute these scores, we use the Faiss library \cite{douze2024faiss}.
Movies were sorted chronologically and processed in yearly batches. For a given batch we queried the Faiss index containing all prior movies to find distances to the nearest neighbor for each movie in the current batch. After that, the current batch was added to the index for subsequent queries.

Results:
In order to assess if temporal trends of novelty scores exist, we plot the average novelty score per year alongside scattered individual movie scores in Figure \ref{fig:novelty_over_time}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/novelty_over_time.png}
    \caption{Novelty scores of movies over time. The blue line represents the average novelty score per year, while individual movie scores are shown as scattered points.}
    \label{fig:novelty_over_time}
\end{figure}

The resulting plot indicates that the average yearly novelty remained relatively constant from 1950s onwards.
TODO: Find better way to plot this, maybe novelty of all movies vs novelty of Oscar nominees?


\subsection{Methodology}

After the data was collected and cleaned, the first step was to embed the movie plot summaries into a semantic space.

\subsubsection{Distance analysis}

Once movie plots are embedded into a unified semantic space, quantitative analysis of their geometric relationships becomes possible through distance metrics. The cosine distance between embeddings provides a natural measure of semantic dissimilarity, enabling the construction of cumulative distribution functions over pairwise distances within defined subsets of the corpus. Such distributions encode structural properties of the embedding space and reveal whether semantic relationships exhibit systematic patterns across temporal periods or thematic categories.

As movie genres provide a meaningful taxonomy with potential temporal evolution patterns, we examine semantic drift across different time periods of an arbitrary number of years. To this end, embeddings are first grouped by genre $g$ into discrete time periods $\tau$, forming the set $\mathcal{M}_g^{(\tau)}$ of plot embeddings. For each group, two alternative representative embeddings are computed: the \textbf{centroid} (arithmetic mean) $\bar{\mathbf{e}}_g^{(\tau)}$ and the \textbf{medoid} (cosine distance minimizer embedding) $\tilde{\mathbf{e}}_g^{(\tau)}$. We computed the following metrics to analyse the drift dynamics across the groups:

\textbf{Genre drift and acceleration: }drift (Equation \ref{eq:drift}) measures displacement between representative embeddings of consecutive periods, capturing how a genre's semantic center evolves over time. Acceleration quantifies the change in drift between consecutive periods.

\begin{equation}
    % === 3. Drift Velocity ===
    \mathbf{d}_g^{(\tau)} = \bar{\mathbf{e}}_g^{(\tau + \Delta t)} - \bar{\mathbf{e}}_g^{(\tau)}
    \label{eq:drift}
\end{equation}
\textbf{Inter genre distance: }determines cosine distance between representatives of each pair of genres for each year, enabling pairwise comparison between specific genres.

Due to group size differences between time periods, two alternative normalization 
approaches have been employed: (1) downsampling, ensuring equal sampling error 
across groups, and (2) z-score normalization, which accounts for the standard 
error of the difference between group means:
\begin{equation}
   \hat{v}_g^{(\tau)} = \frac{v_g^{(\tau)}}{\sigma_{\text{pooled}} \cdot \sqrt{\frac{1}{n_g^{(\tau)}} + \frac{1}{n_g^{(\tau + \Delta t)}}}}
\end{equation}
where $\sigma_{\text{pooled}}$ is the pooled within group standard deviation of cosine distances, and $n_g^{(\tau)}$ is the number of movies in genre $g$ at time $\tau$.


\subsubsection{Kolmogorov-Smirnov test}

To rigorously compare distance distributions across different subsets of movies, for instance films from different decades or belonging to distinct genres or distinct epsilon balls around anchor movies, we employ the Kolmogorov-Smirnov test \cite{massey1951}, a non parametric statistical method for assessing whether two empirical distributions arise from the same underlying continuous distribution.

A key design choice in applying this framework is the selection of a reference point from which distances are computed. One natural approach is to use the mean vector of a baseline subset of movies as a reference embedding, then compute the distribution of distances from this reference point to all movies in the corpus.

In the context of temporal semantic analysis, the KS test enables systematic comparison of distance distributions across decades. By computing distances from fixed reference points (such as mean embeddings of genre clusters) to movies from different decades, we can assess whether the spatial organization of semantic representations evolves over time. If the semantic structure of cinema remains stable over time, distance distributions should remain statistically similar.

To operationalize this framework, we construct epsilon balls around selected anchor movies by collecting all movies within a specified cosine distance threshold, typically $\epsilon \in [0.24, 0.30]$. Given anchor movies representing a specific thematic category (e.g., spy films), all movies within the epsilon ball exhibit high plot similarity to the anchors, defining a local semantic neighborhood. We compare the distance distributions of movies within this epsilon ball to those from a control group (constructed using the mean embedding of all movies) to quantify whether the local semantic structure differs from the global distributional properties. To analyze temporal evolution explicitly, we construct cumulative distribution functions (CDFs) of release years for movies within the epsilon ball and compare them to the corresponding CDFs from the control group. A temporal shift in movie plots manifests as a divergence between these CDFs, indicating that the semantic neighborhood exhibits a different temporal distribution than expected under temporal uniformity. Interpretation of observed temporal shifts is performed by examining historical context and culturally significant events within the relevant time periods.

\section{Results}\label{sec:results}

In this section, we present and interpret the main empirical findings of our analysis on the embedding space of movie plot summaries. Our results address the spatial structure of the embedding space, overall trends in movie similarity, and how key summary statistics illustrate broader cultural and semantic patterns.

\textbf{Spread analysis}
There were 3 metrics used to analyze the spread of movies each year: (1) Mean L2 norm, (2) Frobenius and (3) Spectral norm of each movie to its yearly centroid as defined in section 3.5. All 3 metrics were computed on centered yearly embeddings (i.e. yearly centroid was subtracted from each movie embedding before computing the norms) \cite{yamagiwa2024norm}. We could not interpret much from the results of this analysis of movie spread over the years. Mean L2 norm and Frobenius norm stayed relatively constant at 0.7 and 12.4 respectively. Spectral norm had a slight increase from 2.1 to 2.8. We interpreted this as the overall spread of movies remaining relatively constant over the years with outliers becoming more polarizing. It was hard to determine what these polarizing axis were, as they changed yearly and were a combination of multiple dimensions.

\subsection{General Spatial Analysis}

We begin with an overview of the global structure of the embedding space by examining the pairwise cosine distances between movie embeddings. The distribution of these distances is approximately normal, with a mean cosine distance of $\mu = 0.5195$ and a standard deviation of $\sigma = 0.0624$, measured over multiple samples. This summarizes the typical dissimilarity between movie plots and serves as a reference point for subsequent analyses.

To assess the extent to which genre labels correspond to distinct regions in the embedding space, we analyzed separation metrics across 19 genres. The overall intra-genre distance (mean cosine distance between movies within the same genre) was 0.5042, while the overall inter-genre distance (mean cosine distance between movies from different genres) was 0.5268. This yields a separation ratio of 1.0448 and a separation gap of 0.0226. The proximity of these values, with inter-genre distances only marginally exceeding intra-genre distances, indicates substantial overlap between genre clusters in the semantic space. This interpretation is further supported by a silhouette score of $-0.0334$, where negative values indicate that genres are not well separated and exhibit significant intermingling. These findings suggest that while embeddings capture semantic similarity, genre boundaries in this high dimensional space are relatively porous, reflecting the hybrid and overlapping nature of cinematic categorization.

% I could add the plot but it doesn't show shit
None of the genre based analyses yielded statistically significant results, suggesting that genres may be too broad as analytical categories and any underlying patterns are likely obscured by noise. After normalization, the cosine distance of each time group  epresentative embedding with respect to the previous one remained stochastic. Inter genre analysis yielded the same result. 

\subsection{Kolmogorov-Smirnov test}

We begin by examining a concrete example using James Bond films as anchor movies to assess whether their distance distributions differ from those of randomly selected movies. The cumulative distribution function of cosine distances from the anchor movies to all other movies in the dataset shows an initial steep rise corresponding to other Bond films and thematically related spy movies, which exhibit minimal distances. However, these constitute a small fraction of the corpus, resulting in a CDF that remains close to zero initially before rising more gradually. In contrast, the mean vector curve lies consistently to the left of the anchor curve, indicating that the global mean embedding is more similar to the majority of movies than the highly specific Bond anchor movies. This is expected: the mean embedding represents an average over all narrative types, whereas the Bond anchor is semantically constrained to a narrow subgenre, resulting in greater distances to most films.

To examine the temporal dimension, we construct cumulative distribution functions of release years for movies within the epsilon ball and compare them to the control group. Figure~\ref{fig:ks_test_temporal_bond} shows that the temporal distributions differ markedly. The left panel reveals a divergence beginning approximately in the 1960s, suggesting that the spy movie subgenre represented by the Bond anchor exhibits a distinct temporal emergence pattern compared to the broader corpus. The right panel displays normalized histograms of movie counts per year for both groups, confirming that the temporal distribution of spy-themed films diverges from the overall temporal distribution of cinema. This temporal divergence indicates that the spy film subgenre experienced a period of increased production and thematic consolidation that is not representative of general cinematic trends during the same period.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ks_test_temporal_Spectre__The_World_Is_Not_Enough__Tomorrow_Never_Dies__Casino_Royale__Casino_Royale__GoldenEye__Quantum_of_Sola__501cadb7_eps0.30.png}
    \caption{KS test on temporal distributions for James Bond epsilon ball versus control group. Left: Cumulative distribution functions of release years showing divergence beginning in the 1960s. Right: Normalized histograms of movie counts per year, revealing distinct temporal patterns in spy film production compared to the broader corpus.}
    \label{fig:ks_test_temporal_bond}
\end{figure}

To further validate the methodology, we applied the same framework to movies focused on Middle East conflicts, using anchor movies such as \textit{Black Hawk Down}, \textit{The Hurt Locker}, \textit{Zero Dark Thirty}, and \textit{American Sniper}. Figure~\ref{fig:ks_test_temporal_middle_east} displays the temporal distribution analysis for this thematic category. The temporal shift is even more pronounced than in the spy film case, with the largest divergence occurring prior to the Gulf War period. Following this point, the frequency of movies semantically similar to the anchor movies increases rapidly. This pattern suggests that Middle East conflict films represent a temporally concentrated genre that emerged in response to specific historical events.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ks_test_temporal_Black_Hawk_Down__The_Hurt_Locker__Zero_Dark_Thirty__American_Sniper__Lone_Survivor__13_Hours_The_Secret_Soldier__26dca182_eps0.28.png}
    \caption{KS test on temporal distributions for Middle East conflict films epsilon ball ($\epsilon = 0.28$) versus control group. The temporal divergence is more pronounced than in the spy film case, with the largest difference occurring before the Gulf War period, followed by rapid convergence as production of conflict-themed films increased.}
    \label{fig:ks_test_temporal_middle_east}
\end{figure}

\section{Discussion \& Conclusion}\label{sec:conclusion}

% Use this section to briefly summarize the entire text. Highlight limitations and problems, but also make clear statements where they are possible and supported by the analysis. 

We have utilized modern embedding methods and multiple statistical tools to analyze the evolution of movie plot embeddings over nearly a century of cinema. Our findings indicate that while the overall semantic structure of movie plots remains relatively stable, specific thematic subgenres exhibit distinct temporal emergence patterns. 

We must acknowledge the limitations that arise from our data sources. Wikipedia plot summaries, while standardized, may not fully capture the nuances of original narratives, potentially introducing bias. Additionally, our reliance on a single embedding model, while ensuring a unified semantic space, may overlook temporal linguistic shifts. More importantly, the evolution of cinema is not only reflected in plot summaries but also in cinematography, direction, music, feeling, acting and other non textual elements. Future work could explore multimodal embeddings that integrate visual and auditory features alongside textual data.

\newpage
\newpage

\section*{Contribution Statement}
\textbf{Contribution Statement:}

\begin{itemize}
    \item \textbf{Ansel Cheung:} Performed genre classification analysis, classification of movie plots into genres, and conducted genre drift and PCA analysis of the movie plots.
    \item \textbf{Alessio Villa:} Developed and maintained the IMDb and TMDb API pipelines, and contributed to the related work research and methods background sections.
    \item \textbf{Bartol Markovinović:} Defined the data pipeline cutoff and carried out resulting data cleaning, managed the integration of Wikidata, and conducted novelty score analysis.
    \item \textbf{Martín López de Ipiña:} Carried out genre drift statistical analysis on the general embedding space, performed general spatial analysis of embeddings, and analyzed the cosine distance distributions.
    \item \textbf{Niklas Abraham:} Performed embedding model selection and evaluation, analyzed chunking methods, and performed KS test and distance distribution analysis.
\end{itemize}

\vspace{0.5em}
Overall, all authors contributed equally to the project. This is reflected in the various analysis sections throughout the report, where each member's work formed an integral and balanced part of the final study.


\bibliography{bibliography}
\bibliographystyle{icml2025}

\end{document}

% This document was modified from the files available at https://icml.cc/Conferences/2025/AuthorInstructions
% the full copyright notice is available within the file icml2025.sty