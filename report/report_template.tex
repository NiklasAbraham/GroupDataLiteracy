%!TEX root = report_template.tex

%%%%%%%% DATA LITERACY 2025 LATEX PROJECT TEMPLATE FILE %%%%%%%%%%%%%%%%%
%%% Based on the 2025 ICML template, available at https://icml.cc/Conferences/2025/AuthorInstructions %%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{makecell} % for multi-line table cells
\usepackage{amsmath}   % For \text{}, align environments, better math spacing
\usepackage{amssymb}   % For \mathbb, extra symbols (optional but common)

\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, calc, fit}
% Corporate Design of the University of Tübingen
% Primary Colors
\definecolor{TUred}{RGB}{165,30,55}
\definecolor{TUgold}{RGB}{180,160,105}
\definecolor{TUdark}{RGB}{50,65,75}
\definecolor{TUgray}{RGB}{175,179,183}

% Secondary Colors
\definecolor{TUdarkblue}{RGB}{65,90,140}
\definecolor{TUblue}{RGB}{0,105,170}
\definecolor{TUlightblue}{RGB}{80,170,200}
\definecolor{TUlightgreen}{RGB}{130,185,160}
\definecolor{TUgreen}{RGB}{125,165,75}
\definecolor{TUdarkgreen}{RGB}{50,110,30}
\definecolor{TUocre}{RGB}{200,80,60}
\definecolor{TUviolet}{RGB}{175,110,150}
\definecolor{TUmauve}{RGB}{180,160,150}
\definecolor{TUbeige}{RGB}{215,180,105}
\definecolor{TUorange}{RGB}{210,150,0}
\definecolor{TUbrown}{RGB}{145,105,70}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Project Report Template for Data Literacy 2025}

\begin{document}

\twocolumn[
% \icmltitle{The Geometry of Cinema: Quantifying 75 Years of Cultural Drift}
\icmltitle{Data Literacy 2025 Project Report}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Ansel Cheung}{equal,first}
\icmlauthor{Alessio Villa}{equal,second}
\icmlauthor{Bartol Markovinović}{equal,third}
\icmlauthor{Martín López de Ipi\~na}{equal,fourth}
\icmlauthor{Niklas Abraham}{equal,fifth}
\end{icmlauthorlist}

% fill in your matrikelnummer, email address, degree, for each group member
\icmlaffiliation{first}{Matrikelnummer 7274374, MSc Machine Learning}
\icmlaffiliation{second}{Matrikelnummer 7306912, MSc Computer Science}
\icmlaffiliation{third}{Matrikelnummer 7324790, MSc Machine Learning}
\icmlaffiliation{fourth}{Matrikelnummer 7293076, MSc Machine Learning}
\icmlaffiliation{fifth}{Matrikelnummer 7307188, MSc Machine Learning}

% put your email addresses here. You can use initials to save space, 
% e.g. if you are called Max Mustermann, you can use \icmlcorrespondingauthor{MM}{max.mustermann@uni-tuebingen.de}
% DO USE YOUR UNIVERSITY EMAIL ADDRESS!
\icmlcorrespondingauthor{Initials1}{ansel-heng-yu.cheung@uni-tuebingen.de} 
\icmlcorrespondingauthor{Initials2}{alessio.villa@student.uni-tuebingen.de}
\icmlcorrespondingauthor{Initials3}{bartol.markovinovic@student.uni-tuebingen.de}
\icmlcorrespondingauthor{Initials4}{martin.lopez-de-ipina-munoz@student.uni-tuebingen.de}
\icmlcorrespondingauthor{Initials5}{niklas-sebastian.abraham@student.uni-tuebingen.de}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Cultural narratives encode and transmit evolving societal values, yet quantifying how meanings change over time remains methodologically challenging. This project investigates semantic evolution in cinema by analyzing how genres and thematic clusters shift within a unified semantic space across multiple decades. By representing movies as embeddings and tracking their geometric trajectories measuring velocity, acceleration, and curvature we distinguish periods of gradual semantic drift from moments of structural reorganization in cinematic history. This framework provides a quantitative foundation for understanding cultural change at scale and tests whether established linguistic laws of semantic evolution extend to film as a cultural medium.
\end{abstract}

\section{Introduction}\label{sec:intro}

Cinema provides a rich archive of narrative structures that encode evolving societal values across generations. Stories serve not only to entertain but to instruct, and those narratives that align with existing social values are more likely to survive and propagate through collective memory. Recent computational work has revealed hidden cultural patterns in large narrative corpora. \cite{xu2020cinderella} used word embeddings to uncover systematic gender stereotypes in movie synopses, revealing the "Cinderella complex" where female characters' happiness depends asymmetrically on male characters. \cite{matthews2021genre} applied topic modeling to investigate genre structure and temporal evolution, demonstrating that lexical features capture meaningful genre conventions and showing how genres shift in composition over time. These studies establish that quantitative methods can illuminate cultural phenomena at scales beyond traditional close reading, revealing patterns that operate across thousands of narratives.

However, measuring semantic change in cultural narratives over extended historical periods remains methodologically challenging. Previous approaches have examined genre structure at specific moments or through discrete topic models that capture lexical shifts but not the continuous geometric evolution of semantic categories. Can we characterize not merely that genres change, but how they change whether through gradual drift, sudden discontinuities, or cyclical patterns? Furthermore, while linguistic corpora have been analyzed for semantic drift using diachronic word embeddings, these methods require temporal alignment procedures that introduce potential artifacts when comparing meanings across decades.

We address these questions by constructing a unified semantic space from a large corpus of film plot summaries spanning multiple decades. By embedding all narratives into a single static vector space, we eliminate temporal alignment requirements while preserving fine grained semantic relationships. Within this space, we represent genres and thematic clusters as centroids and track their trajectories over time. By computing geometric properties of these trajectories including velocity, acceleration, and curvature we can distinguish periods of continuous semantic evolution from moments of structural reorganization where genres undergo fundamental conceptual shifts. This geometric analysis reveals not just that meanings change, but the dynamics of how they change, providing quantitative measures of cultural evolution.

\section{Data and Methods}\label{sec:methods}

\subsection{Data Collection}

We constructed our movie corpus using a multi stage pipeline that systematically integrated three complementary sources: Wikidata, The Movie Database (TMDb), and Wikipedia. This approach combines rich structured metadata with the detailed textual content required for semantic analysis.

The first data collection phase queried Wikidata, a collaboratively edited multilingual knowledge graph maintained by the Wikimedia Foundation. Wikidata serves as an ideal entry point for systematic movie data collection due to its comprehensive coverage of cultural artifacts and its structured representation of temporal, categorical, and relational metadata. For each year in our study period, we retrieved movies satisfying specific criteria, including release year, film classification, and the availability of linked Wikipedia articles in English. This step yielded essential metadata fields including unique Wikidata identifiers, film titles, release years, and crucially, sitelinks to corresponding Wikipedia articles.

Second, we enriched the dataset using TMDb, a community driven database that offers quantitative measures of popularity and user engagement. Wikidata's external identifiers enabled direct mapping to TMDb entries, from which we programmatically retrieved vote counts, vote averages, and popularity metrics for each film. These measures served as proxies for audience engagement and cultural impact, informing downstream film filtering and weighting.

The third stage, the most data intensive, focused on obtaining full text plot summaries. Leveraging Wikipedia sitelinks from Wikidata, we accessed each film's Wikipedia page to extract the plot section. Wikipedia's editorial standards ensure relatively uniform and neutral plot descriptions, facilitating standardized comparative semantic analysis. This step used the Wikipedia API for article retrieval, section extraction, and text normalization, transforming metadata into the dense textual data required for downstream embedding.

The last enrichment stage addressed limitations in TMDb voting statistics. Many movies in the corpus lacked TMDb ratings or vote counts, and when available, these counts were often substantially lower than those reported by other platforms. To address this issue, we enriched the dataset with IMDb vote averages and vote counts, obtained from IMDb’s non-commercial data files and merged using the IMDb title identifier. The inclusion of IMDb data ensures broader coverage and higher vote volumes, resulting in a more stable measure of audience reception.

All data sources are open and appropriately licensed. Wikidata \cite{wikidata} is released under CC0 1.0 Universal (public domain). Wikipedia \cite{wikipedia} is under CC BY SA 4.0, and TMDb \cite{tmdb} under CC BY NC 4.0, allowing non commercial research with attribution. This ensures reproducibility and legal compliance.

Our final dataset achieves high coverage, with plot summaries for over 80\% of films in most decades (see Table \ref{tab:decade_coverage}).

\begin{table}[ht]
    \centering
    \caption{Per decade feature coverage (\%) of key metadata fields in the movie dataset.}
    \begin{tabular}{lcccc}
        \toprule
        Decade & Actors+Director  & Genre & Plot & Vote Count \\
        \midrule
        1950s   & 86.56  & 63.67 & 83.03 & 90.19 \\
        1960s   & 83.82  & 61.01 & 77.31 & 85.26 \\
        1970s   & 86.55  & 62.47 & 79.57 & 86.58 \\
        1980s   & 84.68  & 59.41 & 79.80 & 85.41 \\
        1990s   & 82.22  & 58.33 & 82.00 & 84.49 \\
        2000s   & 77.34  & 60.51 & 84.19 & 83.73 \\
        2010s   & 70.25  & 60.55 & 84.94 & 85.60 \\
        2020s   & 70.66  & 64.85 & 77.59 & 89.63 \\
        \midrule
        Average & 80.26  & 61.35 & 81.05 & 86.36 \\
        \bottomrule
    \end{tabular}
    \label{tab:decade_coverage}
\end{table}

After the data was collected in a tabular format, the textual plot descriptions required transformation into vector representations via a suitable embedding model for downstream analysis. The plot descriptions extracted from Wikipedia pages exhibit substantial variability in length, ranging from 10 to 20,479 characters, corresponding to approximately 6 to 5,296 tokens in a english tokenizer. All plot descriptions in our corpus are in English, which simplifies the embedding process by eliminating cross lingual considerations.


\subsection{Methodology}

After the data was collected and cleaned, the first step was to embed the movie plot summaries into a semantic space.

The selection of an appropriate embedding model was guided by the Massive Text Embedding Benchmark (MTEB) leaderboard results\footnote{\url{https://huggingface.co/spaces/mteb/leaderboard}}, which provides comprehensive evaluations of embedding models across diverse retrieval and semantic similarity tasks. Based on these benchmarks, we selected the BGE-M3 (Beijing Academy of Artificial Intelligence Multilingual, Multifunctional, Multi-granularity) model \cite{chen2024bgem3embeddingmultilingualmultifunctionality}, an open-source model developed by the Beijing Academy of Artificial Intelligence. The BGE-M3 model achieved competitive performance (28th place on the MTEB leaderboard) while maintaining a relatively compact architecture with 0.5 billion parameters. Critically, the model supports a context length of 8,192 tokens, which enables embedding entire movie plot descriptions into a single vector representation without requiring chunking.

The BGE-M3 model provides three embedding modes: a dense vector (global document representation via [CLS]), a sparse vector (high-dimensional token weights for lexical matching), and a multi-vector mode (token-level semantic representations for each word in the input).

A key methodological choice was to use a single, static embedding model for all time periods, rather than training separate or temporally aligned models. This ensures all film plots are represented in a unified latent space, avoiding complex post-hoc alignment and minimizing artifacts. While movies from earlier decades describe very different world view with a different language and culture, the Wikipedia-based plot summaries are not contemporaneous texts from those eras, instead, they are modern English descriptions collectively maintained and updated since Wikipedia's founding in 2001. Thus, any linguistic variation or semantic drift in the summaries themselves is minimal. We rely on this assumption of consistent descriptive language to enable direct, meaningful comparisons of embedding-based semantics across decades, without additional alignment steps.

Embedding variable-length documents presents challenges for transformer-based models due to fixed context windows and representational biases. Because plot summaries in our dataset span from a few sentences to thousands of words, it is crucial to select chunking and pooling strategies that minimize length bias while retaining semantic content. Relying solely on the [CLS] token for global representation can introduce substantial bias: it is sensitive to input length, often overemphasizes the first ~128 tokens \cite{DBLP:journals/corr/abs-1810-04805, pmlr-v97-gong19a}, and underperforms mean pooling on long documents \cite{raffel2023exploringlimitstransferlearning}. With over 75\% of our plots exceeding 512 tokens, a more robust aggregation method is required to avoid discarding information.

There were four main document embedding methods evaluated: (1) Mean Pooling: compute the average of token embeddings to form the document vector; (2) Early Chunk-then-Embed: split the document into chunks before embedding and average their vectors, reducing length effects but limiting cross-chunk context; (3) Late Embed-then-Chunk: embed the full document, then aggregate over sliding windows to capture broader context; (4) CLS Token: use the pretrained [CLS] token as a summary. Each method offers a different tradeoff between bias, variance, and preservation of semantic details.

% We evaluated four main document embedding methods, illustrated in Figure \ref{fig:chunking_methods}:
%\begin{figure}[ht]
%\centering
%    \includegraphics[width=8cm]{figures/data_preprocess/plot_different_chunking.png}
%    \caption{Comparison of chunking methods: (a) Mean Pooling, (b) Early Chunk-then-Embed, (c) Late Embed-then-Chunk.}
%    \label{fig:chunking_methods}
%\end{figure}

Once movie plots are embedded into a unified semantic space, quantitative analysis of their geometric relationships becomes possible through distance metrics. The cosine distance between embeddings provides a natural measure of semantic dissimilarity, enabling the construction of cumulative distribution functions over pairwise distances within defined subsets of the corpus. Such distributions encode structural properties of the embedding space and reveal whether semantic relationships exhibit systematic patterns across temporal periods or thematic categories.

To rigorously compare distance distributions across different subsets of movies, for instance films from different decades or belonging to distinct genres, we employ the Kolmogorov-Smirnov test, a non parametric statistical method for assessing whether two empirical distributions arise from the same underlying continuous distribution \cite{massey1951}. The two sample KS test compares the empirical cumulative distribution functions (ECDFs) of two samples by computing the maximum vertical distance between them.

Formally, given two samples \( X_1, \ldots, X_n \) and \( Y_1, \ldots, Y_m \), their empirical cumulative distribution functions are defined as:
\begin{equation}
F_n(x) = \frac{1}{n} \sum_{i=1}^{n} 1_{X_i \leq x}, \quad G_m(y) = \frac{1}{m} \sum_{j=1}^{m} 1_{Y_j \leq y}
\end{equation}
where \( 1 \) denotes the indicator function. The KS test statistic is defined as the supremum of absolute differences between these ECDFs:
\begin{equation}
D_{n,m} = \sup_{x} |F_n(x)   G_m(x)|
\end{equation}

Under the null hypothesis that both samples are drawn from the same continuous distribution, the distribution of \( D_{n,m} \) is known and can be used to compute p values for hypothesis testing. The test is particularly suited for our application because it makes no assumptions about the underlying distributional form, is sensitive to differences in both location and shape, and operates directly on the distance measurements without requiring binning or parametric modeling.

A key design choice in applying this framework is the selection of a reference point from which distances are computed. One natural approach is to use the mean vector of a baseline subset of movies as a reference embedding, then compute the distribution of distances from this reference point to all movies in the corpus. This baseline distribution can then serve as a comparison standard against which distance distributions from other subsets are evaluated. For instance, the mean embedding of movies from a particular decade or genre can be computed, and the resulting distance distribution compared against the baseline using the KS test to assess whether the subset exhibits systematically different spatial organization relative to the reference.

In the context of temporal semantic analysis, this framework enables systematic comparison of distance distributions across decades. If the semantic structure of cinema remains stable over time, distance distributions should remain statistically similar. Conversely, significant differences in these distributions, as detected by the KS test, would indicate structural reorganization of the semantic space, suggesting periods where narrative conventions undergo fundamental shifts. By applying this analysis to distances measured from fixed reference points in the embedding space, we can quantify how the density and dispersion of semantic representations evolve temporally, providing a complementary perspective to trajectory based analyses of genre evolution.

\subsection{Genre analysis}
\input{stuff/genre_analysis.tex}

\textbf{Projection along temporal axis}
This idea is to select an arbitrary vector that is in the embedding space and project the movie embeddings onto this vector. Based on the choice of this vector, we will be able to see how much of each movie embedding lies on the vector, and we can then do temporal analysis to see how this metric evolves over time. Since our embeddings are already normalized to magnitude 1, cosine distance is proportional to L2 norm, which measures euclidean distance between embeddings. Note that for this Projection Analysis, all experiments were bootstrapped for 500 times, 1000 samples.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/projection_analysis_action_1930_2024.png}
    \caption{Projection onto action vector over years}
    \label{fig:proj_analysis_action}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/projection_analysis_romance.png}
    \caption{Projection onto Romance vector over years}
    \label{fig:proj_analysis_romance}
\end{figure}

First vector we chose was $mean(\text{emb}_{\text{action 2024}}) - mean(\text{emb}_{\text{action 1930}})$. From Figure \ref{fig:proj_analysis_action}, we can see that movie plots are increasingly becoming similar to action movie plots. If we look at Figure \ref{fig:proj_analysis_romance} we also see the same trend for Romance. This created suspicion and we plotted the same thing but the overall centroid shift from 1930 to 2024 and also saw the same plots (Figure \ref{fig:proj_analysis_overall}). This could mean that how movie plots evolve over time outweighs the shift in genres. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/projection_analysis_overall.png}
    \caption{Projection onto Mean vector over years}
    \label{fig:proj_analysis_overall}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/action_cosine_dist.png}
    \caption{Action cosine distance to mean (all) embedding vector}
    \label{fig:action_cos_dist}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/romance_cosine_dist.png}
    \caption{Romance cosine distance to mean (all) embedding vector}
    \label{fig:romance_cos_dist}
\end{figure}

In order to then explore the shift in genres over time, we plotted the Cosine Distance evolution of mean action embedding per year from the overall centroid. From Figure \ref{fig:action_cos_dist} we observe that the action movies are getting more and more similar to the average embedding vector. The Romance cosine distance to the same mean vector shows a different story (Figure \ref{fig:romance_cos_dist}). 

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/all_cosine_dist.png}
    \caption{All genre's cosine distance to mean (all) embedding vector}
    \label{fig:all_cos_dist}
\end{figure}

Figure \ref{fig:all_cos_dist} We expanded this to our new genres and this revealed that many large genres were converging towards the mean embedding. There are some outliers such as "Anime" which only appeared after 1980. "Film Noir" and "Adventure and Fantasy" did not follow the trend of converging towards the mean embedding. (do I end here?)

\textbf{Spread analysis}
Another way to see if movies are converging over the years or spreading out is to measure the spread per year. (https://arxiv.org/pdf/1810.08693) Frobenius norm measures the total variance of each year's difference in movie embeddings to its yearly mean embedding. The frobenius norm (https://arxiv.org/pdf/1501.01571 page 84 ) is the sum of squared singular values in which we are only measuring noise and not the signal. In order to see the signal shift, we use the spectral norm to find the maximum singular value of the difference in movie embeddings and their respective yearly mean embeddings.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/spread_analysis_mean_l2_norm.png}
    \caption{Mean L2 Norm vs Cosine Distance against yearly centroid}
    \label{fig:mean_l2_norm}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/spread_analysis_frob_spec_norm.png}
    \caption{Spectral and Frobenius Norm of yearly movies against yearly centroid}
    \label{fig:frob_spec_norm}
\end{figure}

We observe from Figure \ref{fig:mean_l2_norm} that movies are getting getting more and dissimilar. Paired together with the mean L2 distance from each movie to the yearly mean embedding, we can see that the average distance from each movie to its yearly mean remains the same, but the spectral norm triples in size (Figure \ref{fig:frob_spec_norm}), signalling that there is some sort of shape shift or stretching of the embedding cloud. There is a sharp drop in 2020, which might be attributed to movie production during covid period reducing the number of movies being produced and hence reducing the chance for outliers.

\begin{figure}[ht]
    \centering
    \includegraphics[width=8cm]{figures/ansel/spread_analysis_pve.png}
    \caption{PC1 Explained Variance of yearly movies against yearly centroid}
    \label{fig:pve_yearly}
\end{figure}

The next sensible step to take is to analyze the explained variance of the first principal component. This can simply be calculated by the squared spectral norm divided by the squared frobenius norm. From Figure \ref{fig:pve_yearly}, the explained variance increases from 3\% to 4\% and sharply rises to 4.75\% after 2020. An explained variance of 4\% is significant in a dataset with dimension of 1024. If all dimensions were random noise, each PC would explain $1/1024 \approx 0.098\%$, so 4\% is 40 times higher than random. This means that there is a direction which is polarizing the movie industry. 

This is actually one large circular path leading back to PCA. Now we can interpret the evolution of movies to see which movies are the most polarized by that particular year's principal component. Hence we project every movie's embeddings onto its year's PC. From here we select an arbitrary number of years to analyze its top and bottom 5 movies.

(PCA1 table here)

(PCA US Movies)

(PCA German Movies)


\section{Results}\label{sec:results}

\subsection{Chunking Method Comparison}

We evaluated ten distinct embedding strategies across 5,000 movie plot descriptions, comprising four fundamental approaches with various parameterizations: Mean Pooling, CLS Token extraction, Chunk First Embed with three configurations (512/256, 1024/512, 2048/1024 tokens for chunk size and stride), and Late Chunking with six configurations. The evaluation employed multiple metrics to assess embedding quality, including length bias, isotropy, genre classification performance, and class separation characteristics. Table \ref{tab:chunking_results} presents key performance metrics across all methods.

\begin{table*}[ht]
    \centering
    \caption{Comparative performance of chunking methods across key evaluation metrics. Length Norm Corr measures correlation between document length and embedding norm. Isotropy (1st PC) indicates variance concentration in the first principal component (lower is better). Genre Acc and F1 report classification performance. Silhouette measures cluster cohesion. Sep. Ratio quantifies intra class to inter class similarity ratio.}
    \label{tab:chunking_results}
    \small
    \begin{tabular}{lcccccc}
        \toprule
        Method & \makecell{Length-Norm\\Corr} & \makecell{Isotropy\\(1st PC \%)} & \makecell{Genre\\Acc} & \makecell{Genre\\F1} & Silhouette & \makecell{Sep.\\Ratio} \\
        \midrule
        Mean Pooling & 0.629 & 11.36 & 0.326 & 0.180 & -0.036 & 0.943 \\
        CLS Token & 0.004 & 3.32 & 0.341 & 0.194 & -0.016 & 0.958 \\
        \midrule
        Chunk-First 512/256 & -0.366 & 3.47 & 0.349 & 0.198 & -0.020 & 0.951 \\
        Chunk-First 1024/512 & -0.275 & 3.37 & 0.348 & 0.197 & -0.017 & 0.959 \\
        Chunk-First 2048/1024 & -0.031 & 3.33 & 0.341 & 0.194 & -0.016 & 0.961 \\
        \midrule
        Late Chunk 512/256 & 0.822 & 11.92 & 0.327 & 0.180 & -0.037 & 0.949 \\
        Late Chunk 1024/512 & 0.726 & 11.53 & 0.326 & 0.181 & -0.037 & 0.948 \\
        Late Chunk 2048/1024 & 0.656 & 11.36 & 0.326 & 0.180 & -0.036 & 0.958 \\
        Late Chunk 2048/512 & 0.656 & 11.36 & 0.326 & 0.180 & -0.036 & 0.958 \\
        Late Chunk 512/0 & 0.821 & 11.40 & 0.328 & 0.183 & -0.037 & 0.948 \\
        \bottomrule
    \end{tabular}
\end{table*}

\textbf{Length Bias and Correlation:} The length-normalization correlation metric reveals substantial variation across methods. MeanPooling and LateChunking variants exhibit positive correlations ranging from 0.62 to 0.82, with LateChunking\_512\_256 achieving the highest value (0.82). In contrast, CLSToken demonstrates near-zero correlation (0.0035), while ChunkFirstEmbed methods show negative correlations ranging from -0.03 to -0.37, with ChunkFirstEmbed\_512\_256 exhibiting the strongest negative correlation (-0.37).

\textbf{Isotropy Measurements:} Isotropy, measured by the proportion of variance captured in the first principal component, shows a clear distinction between method families. MeanPooling and LateChunking variants demonstrate substantially lower isotropy (first PC: 11.27-11.92\%), indicating more uniformly distributed embeddings across dimensions. CLSToken and ChunkFirstEmbed methods exhibit significantly higher isotropy (first PC: 3.32-3.47\%), suggesting greater concentration of variance along principal axes. After removing the top two principal components, isotropy values converge to a narrower range (2.27-3.09\%) across all methods.

\textbf{Genre Classification Performance:} Genre classification accuracy, evaluated using a logistic regression classifier, demonstrates modest variation across methods. Accuracy ranges from 0.326 to 0.349, with ChunkFirstEmbed\_1024\_512 achieving the highest accuracy (0.349) and LateChunking\_512\_256 the lowest (0.327). Macro-averaged F1 scores similarly cluster between 0.179 and 0.198, with ChunkFirstEmbed methods showing slight superiority (F1: 0.193-0.198) over LateChunking and pooling-based approaches (F1: 0.178-0.183). Silhouette scores, measuring cluster cohesion, remain consistently negative across all methods (ranging from -0.037 to -0.016), indicating substantial overlap in genre representations.

\textbf{Class Separation Metrics:} Intra-class cosine similarity (mean similarity within genre groups) exhibits narrow variation from 0.500 to 0.533 across methods. Inter-class similarity (mean similarity between different genres) similarly ranges from 0.481 to 0.509. The resulting separation ratios, computed as the ratio of intra-class to inter-class similarity, range from 0.943 to 0.962, with ChunkFirstEmbed\_2048\_1024 achieving the highest separation (0.961). Separation gaps, defined as the difference between intra- and inter-class similarity, range from 0.019 to 0.030, with MeanPooling showing the largest gap (0.030) and ChunkFirstEmbed\_2048\_1024 the smallest (0.019).

\textbf{Cosine Similarity Distributions:} The distribution of pairwise cosine similarities across methods reveals consistent central tendencies with mean similarities clustering between 0.485 and 0.505. Standard deviations range from 0.061 to 0.126, with MeanPooling and LateChunking methods exhibiting higher variance (std: 0.123-0.126) compared to CLSToken and ChunkFirstEmbed approaches (std: 0.061-0.067). Minimum observed similarities span from 0.054 to 0.261, while maximum similarities range from 0.688 to 0.836, indicating that MeanPooling and LateChunking methods produce wider similarity distributions.

\textbf{Parameter Sensitivity in Late Chunking:} Within the LateChunking family, window size and stride parameters demonstrate measurable effects on performance characteristics. Configurations with stride 0 (non-overlapping windows) show slightly improved silhouette scores (from -0.037 to -0.037 compared to overlapping configurations). Larger window sizes (2048 tokens) consistently yield higher separation ratios (0.958) compared to smaller windows (512 tokens: 0.943-0.948).

\section{Literature and Methods Review}

\subsection{Semantic Representation and Cultural Patterns}
Our use of word embeddings to represent narrative content draws significant inspiration from the work of \textit{Xu et al. (2019)}. In their study of the "Cinderella Complex" the authors demonstrated that high-dimensional vector spaces can capture latent social biases and emotional dependencies within movie synopses. While \textit{Xu et al.} focused on the internal dynamics of characters and gender stereotypes, our research shifts the lens toward the \textbf{inter-textual relationships} between films. By embedding Wikipedia plots, we treat the narrative as a holistic semantic unit, allowing us to map the entire "cinematic universe" into a geometric space where thematic similarity is measured by vector proximity.

\subsection{Quantifying Novelty and Innovation}
To define and measure "novelty" we adopt the theoretical framework proposed by \textit{Sreenivasan (2013)}, who defines cultural innovation as the emergence of atypical combinations of elements. However, our methodology diverges from Sreenivasan’s reliance on keyword frequencies and probabilistic modeling. Instead, we utilize \textbf{Geometric Distance Analysis}. In our model, novelty is operationalized as the distance of a movie vector from its $k$-nearest neighbors in the embedding space. This allows for a more nuanced detection of innovation: a film is considered "novel" if its semantic coordinates lie in a sparse region of the vector space, indicating a narrative structure that is mathematically distant from established conventions.

\subsection{Diachronic Evolution and Genre Trajectories}
The temporal dimension of our analysis is informed by the diachronic architectures discussed by \textit{Hamilton et al. (2016)}. Their research into how word meanings shift over time provides a blueprint for our analysis of genre evolution. By calculating the \textbf{centroid} of specific genres across different decades, we track their ``semantic drift.'' This approach allows us to test hypotheses regarding cultural homogenization versus diversification, a concept explored in the musical domain by \textit{Di Marco et al. (2025)}. While \textit{Di Marco et al.} utilized network science to observe the simplification of musical structures, we apply these concepts to text, observing whether movie genres are converging toward a standard ``formula'' or expanding into new, unexplored territories of the embedding world.

\section{Discussion \& Conclusion}\label{sec:conclusion}

% Use this section to briefly summarize the entire text. Highlight limitations and problems, but also make clear statements where they are possible and supported by the analysis. 

\newpage

\section*{Contribution Statement}
% Explain here, in one sentence per person, what each group member contributed. For example, you could write: Max Mustermann collected and prepared data. Gabi Musterfrau and John Doe performed the data analysis. Jane Doe produced visualizations. All authors will jointly wrote the text of the report. Note that you, as a group, a collectively responsible for the report. Your contributions should be roughly equal in amount and difficulty.

% \section*{Notes} 
% Your entire report has a \textbf{hard page limit of 4 pages} excluding references and the contribution statement. (I.e. any pages beyond page 4 must only contain the contribution statement and references). Appendices are \emph{not} possible. But you can put additional material, like interactive visualizations or videos, on a githunb repo (use \href{https://github.com/pnkraemer/tueplots}{links} in your pdf to refer to them). Each report has to contain \textbf{at least three plots or visualizations}, and \textbf{cite at least two references}. More details about how to prepare the report, inclucing how to produce plots, cite correctly, and how to ideally structure your github repo, will be discussed in the lecture, where a rubric for the evaluation will also be provided.


\bibliography{bibliography}
\bibliographystyle{icml2025}

\end{document}

% This document was modified from the files available at https://icml.cc/Conferences/2025/AuthorInstructions
% the full copyright notice is available within the file icml2025.sty